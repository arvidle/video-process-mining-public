# Define activity recognizer
# Define activity trace
# Define activity log
import pandas as pd
import numpy as np
from video_pm.tracking import TrackingResults
import pickle
from typing import List, Tuple
from typing_extensions import Self
import datetime
import pm4py

VIDEO_WIDTH = 854
VIDEO_HEIGHT = 480
PREDICT_STEPSIZE = 32
FPS = 30
ACTIONS = ["lying", "sitting", "standing", "moving", "investigating", "feeding", "defecating", "playing", "other"]


class ActionDetectionResults:
    """
    Action detection is run on tracking results.
    After the action detection is run, the detected actions can be added to the tracking results.
    The combined information contains tracklets with activity annotations.
    """
    def __init__(self,
                 action_detection_results: pd.DataFrame, assign_case_ids: bool = True):
        """

        :param action_detection_results: Action detection results as pandas DataFrame
        :param assign_case_ids: Whether to assign new case IDs to the action log
        """
        self.action_detection_results: pd.DataFrame = action_detection_results
        if assign_case_ids:
            self.action_detection_results["case_id"] = self.assign_case_ids()

    def assign_case_ids(self, start_id: int = 1) -> pd.Series:
        """Assign incremental case IDs based on the tracklets.

        A start value for the case IDs can be specified.

        :param start_id: Inital ID value to increment from
        :return: Series of case IDs aligned to the action log
        """
        track_ids = self.action_detection_results["track_id"].unique()
        case_ids = np.arange(len(track_ids)) + start_id
        track_case_map = dict(zip(track_ids, case_ids))
        return self.action_detection_results["track_id"].apply(lambda x: track_case_map[x])

    def concat(self, other: Self) -> Self:
        """Concatenate another action log onto this action log

        :param other: Log to concatenate
        :return: The concatenated logs
        """
        last_case_id = self.action_detection_results["case_id"].max()
        next_case_id = last_case_id + 1

        # Reassign case IDs in the second dataframe to avoid overlapping case IDs between the two action logs
        other_new_case_ids = other.assign_case_ids(start_id=next_case_id)
        other_log = other.action_detection_results.copy()
        other_log["case_id"] = other_new_case_ids

        res_df = pd.concat((self.action_detection_results, other_log), ignore_index=True)

        return ActionDetectionResults(res_df, assign_case_ids=False)

    def segment(self, n_segments: int) -> List[Tuple[float, float, Self]]:
        """Segment the action log into a specified number of equal width temporal segments

        :param n_segments: Number of segments
        :return: List of segmented logs
        """
        start_t = self.action_detection_results["t"].min()
        end_t = self.action_detection_results["t"].max()
        log_length = end_t - start_t
        segment_size = log_length / n_segments
        start_segments = [start_t + segment_size * x for x in range(n_segments)]
        end_segments = [x + segment_size for x in start_segments]
        segments = list(zip(start_segments, end_segments))

        res_segments = []
        for start, end in segments:
            log = self.action_detection_results
            log_segment = log[(start <= log["t"]) & (log["t"] < end)]
            res_segments.append((start, end, ActionDetectionResults(log_segment.copy())))

        return res_segments

    def to_file(self, filename):
        """Write the action log to a file using pickle

        :param filename: Filename to write the object to
        :return:
        """
        with open(filename, "wb") as file:
            pickle.dump(self.action_detection_results, file)

    @classmethod
    def from_file(cls, filename):
        """Load an action detection log from a pickle file

        :param filename: Filename to load the object from
        :return: ActionDetectionResults instance loaded from the specified pickle file
        """
        with open(filename, "rb") as file:
            action_detection_results = pickle.load(file)

        return cls(action_detection_results)

    @classmethod
    def from_mmaction_pkl(cls, detections_filename: str, tracking_results: TrackingResults, start_time: datetime.datetime):
        """Load action detection results generated by a mmaction2 detector.

        After loading the pickled results, they are correlated to the TrackingResults used by the mmaction2 detector.
        This recovers previously known tracklets and makes them available in the action log context.

        :param detections_filename: Filename of the mmaction2 detection results pickle file
        :param tracking_results: TrackingResults instance of the tracking data used by the mmaction2 detector
        :param start_time: Starting timestamp of the video used to assign timestamps to the results
        :return: ActionDetectionResults instance containing the loaded data
        """
        # group tracking by frame
        # Load the pickle data as dict
        # For all keys in the action dict (i.e. frames)
        #   Get the indices of the frame boxes to align the action detection results
        #   Get the action detection results as a list
        #   Sanity check: Action detection box and tracking box should equal in each row
        with open(detections_filename, "rb") as file:
            detections = dict(pickle.load(file))

        tracking_by_frame = tracking_results.tracking.groupby("frame")

        all_indices = []
        all_labels = []

        for key in sorted(detections.keys()):
            frame_boxes = tracking_by_frame.get_group(key)
            frame_indices = frame_boxes.index.to_list()
            frame_labels = [dict(zip(row[1], row[2])) for row in detections[key]]
            all_indices += frame_indices
            all_labels += frame_labels

            action_bboxes = np.vstack([row[0] for row in detections[key]])
            action_bboxes[:, [0, 2]] *= VIDEO_WIDTH
            action_bboxes[:, [1, 3]] *= VIDEO_HEIGHT
            action_bboxes_int = action_bboxes.astype(int)
            frame_bboxes = frame_boxes[["x1", "y1", "x2", "y2"]].to_numpy()

            # Sanity check that all action labels are assigned to the correct bounding boxes
            assert np.array_equal(action_bboxes_int, frame_bboxes)

        aligned_actions = pd.Series(all_labels, index=all_indices, name="actions")

        # Expand the action detection labels from dict format to one column for each action
        def action_expand_fn(action):
            fn = lambda x: x[action] if action in x.keys() else 0
            return fn

        action_fns = [action_expand_fn(action) for action in ACTIONS]
        action_series = [aligned_actions.map(fn).rename(action) for action, fn in zip(ACTIONS, action_fns)]

        detection_df = pd.merge(tracking_results.tracking, pd.concat(action_series, axis=1), left_index=True, right_index=True)
        # Calculate timestamps
        steps = detection_df["frame"].map(lambda x: int((x + 1) / PREDICT_STEPSIZE - 1))
        secs = steps * PREDICT_STEPSIZE / FPS
        detection_df["t"] = secs.apply(lambda x: start_time + datetime.timedelta(seconds=x))

        return cls(detection_df)


class ActivityLog:
    """An activity log resulting from event-activity abstraction.

    Contains abstracted activities correlated to tracklets, but
    """
    def __init__(self, activity_log: pd.DataFrame):
        self.activity_log: pd.DataFrame = activity_log

    def to_file(self, filename):
        """Write the action log to a file using pickle

        :param filename: Filename to write the object to
        :return:
        """
        with open(filename, "wb") as file:
            pickle.dump(self.activity_log, file)

    @classmethod
    def from_file(cls, filename):
        """Load an action detection log from a pickle file

        :param filename: Filename to load the object from
        :return: ActionDetectionResults instance loaded from the specified pickle file
        """
        with open(filename, "rb") as file:
            activity_log = pickle.load(file)

        return cls(activity_log)
